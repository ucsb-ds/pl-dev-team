# -*- coding: utf-8 -*-
"""CS5A.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OnBaLCemBzoSk0IQTxGcqXY_TT3E4FWB
"""

#!/usr/bin/env python3
"""
PrairieLearn Question Analysis: Detecting Pedagogical Patterns
Analyzes question performance data to identify potential "question smells"
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load the question statistics
df = pd.read_csv('CMPSC_5A_F25_E1_question_stats.csv')

print("=" * 80)
print("PRAIRIELEARN QUESTION ANALYSIS")
print("=" * 80)
print(f"\nAnalyzing {len(df)} questions from CMPSC 5A Summer F25, EXAM 1\n")

# Extract key metrics
df['first_sub_score'] = df['First sub. score average'] * 100
df['discrimination'] = df['Discrim.']
df['avg_attempts'] = df['Num. Sub. average']
df['perfect_rate'] = df['Some perfect sub. (%)']
df['zero_rate'] = 100 - df['Some nonzero sub. (%)']

# Parse quintile scores (they're stored as strings like "[86.27,94.12,98.04,100,100]")
def parse_quintiles(q_str):
    """Parse quintile scores from string representation"""
    try:
        # Remove brackets and split by comma
        scores = q_str.strip('[]').split(',')
        return [float(s) for s in scores]
    except:
        return [np.nan] * 5

df['quintiles'] = df['Quintile Scores'].apply(parse_quintiles)
df['Q1_score'] = df['quintiles'].apply(lambda x: x[0] if len(x) > 0 else np.nan)
df['Q5_score'] = df['quintiles'].apply(lambda x: x[4] if len(x) > 4 else np.nan)
df['quintile_spread'] = df['Q5_score'] - df['Q1_score']

print("=" * 80)
print("1. QUESTION SMELL DETECTION")
print("=" * 80)

# Define smell detection criteria
smells = []

for idx, row in df.iterrows():
    question_smells = []

    # SMELL 1: "Too Easy" (Floor Effect)
    if row['first_sub_score'] > 95 and row['discrimination'] < 35:
        question_smells.append({
            'smell': 'TOO_EASY',
            'severity': 'MEDIUM',
            'description': 'Very high first-attempt success with low discrimination',
            'evidence': f"First-sub: {row['first_sub_score']:.1f}%, Discrim: {row['discrimination']:.1f}"
        })

    # SMELL 2: "Too Hard" (Ceiling Effect)
    if row['first_sub_score'] < 75:
        severity = 'HIGH' if row['first_sub_score'] < 65 else 'MEDIUM'
        question_smells.append({
            'smell': 'TOO_HARD',
            'severity': severity,
            'description': 'Low first-attempt success suggests prerequisite gap or poor scaffolding',
            'evidence': f"First-sub: {row['first_sub_score']:.1f}%, Zero scores: {row['zero_rate']:.1f}%"
        })

    # SMELL 3: "Discrimination Failure"
    if 60 <= row['first_sub_score'] <= 90 and row['discrimination'] < 30:
        question_smells.append({
            'smell': 'LOW_DISCRIMINATION',
            'severity': 'MEDIUM',
            'description': 'Question does not distinguish between strong/weak students',
            'evidence': f"Discrim: {row['discrimination']:.1f} (expected >30 for medium difficulty)"
        })

    # SMELL 4: "Quintile Collapse"
    if not np.isnan(row['quintile_spread']) and row['quintile_spread'] < 20:
        question_smells.append({
            'smell': 'QUINTILE_COLLAPSE',
            'severity': 'LOW',
            'description': 'All student groups perform similarly - question may not reveal understanding differences',
            'evidence': f"Q1-Q5 spread: {row['quintile_spread']:.1f}%"
        })

    # SMELL 5: "Bottom Quintile Failure"
    if not np.isnan(row['Q1_score']) and row['Q1_score'] < 40:
        question_smells.append({
            'smell': 'BOTTOM_QUINTILE_FAILURE',
            'severity': 'HIGH',
            'description': 'Weakest students completely lost - possible hidden dependency',
            'evidence': f"Q1 score: {row['Q1_score']:.1f}%"
        })

    if question_smells:
        smells.append({
            'question': row['Question title'],
            'qid': row['QID'],
            'topic': row['Question topic'],
            'smells': question_smells
        })

# Print smell report
print(f"\nðŸ” Found {len(smells)} questions with detected smells:\n")

for item in smells:
    print(f"ðŸ“Œ {item['question']} ({item['topic']})")
    print(f"   QID: {item['qid']}")
    for smell in item['smells']:
        severity_icon = {'HIGH': 'ðŸ”´', 'MEDIUM': 'ðŸŸ¡', 'LOW': 'ðŸŸ¢'}
        print(f"   {severity_icon[smell['severity']]} {smell['smell']}: {smell['description']}")
        print(f"      Evidence: {smell['evidence']}")
    print()

print("=" * 80)
print("2. QUESTION PERFORMANCE SUMMARY")
print("=" * 80)

summary_df = df[['Question title', 'Question topic', 'first_sub_score', 'discrimination',
                  'avg_attempts', 'perfect_rate', 'zero_rate', 'Q1_score', 'Q5_score']].copy()
summary_df = summary_df.round(1)

print("\n" + summary_df.to_string(index=False))

print("\n" + "=" * 80)
print("3. KEY INSIGHTS FOR RESEARCH QUESTIONS")
print("=" * 80)

# Insight 1: Difficulty distribution
print("\nðŸ“Š Difficulty Distribution:")
print(f"   Very Easy (>95% first-sub): {len(df[df['first_sub_score'] > 95])} questions")
print(f"   Appropriate (75-95%):        {len(df[(df['first_sub_score'] >= 75) & (df['first_sub_score'] <= 95)])} questions")
print(f"   Challenging (<75%):          {len(df[df['first_sub_score'] < 75])} questions")

# Insight 2: Discrimination patterns
print("\nðŸŽ¯ Discrimination Quality:")
avg_discrim = df['discrimination'].mean()
print(f"   Average discrimination: {avg_discrim:.1f}")
print(f"   High discrimination (>40): {len(df[df['discrimination'] > 40])} questions")
print(f"   Low discrimination (<30):  {len(df[df['discrimination'] < 30])} questions")

# Insight 3: Attempt patterns
print("\nðŸ”„ Attempt Patterns:")
print(f"   Average attempts across all questions: {df['avg_attempts'].mean():.2f}")
print(f"   Note: Very low attempt counts suggest either:")
print(f"         (a) Questions are well-calibrated OR")
print(f"         (b) Students give up after one attempt")

# Insight 4: Quintile analysis
print("\nðŸ“ˆ Performance Spread:")
avg_spread = df['quintile_spread'].mean()
print(f"   Average Q1-Q5 spread: {avg_spread:.1f}%")
print(f"   Wide spread (>30%): {len(df[df['quintile_spread'] > 30])} questions - good differentiation")
print(f"   Narrow spread (<20%): {len(df[df['quintile_spread'] < 20])} questions - limited differentiation")

print("\n" + "=" * 80)
print("4. PRIORITY QUESTIONS FOR REVISION")
print("=" * 80)

# Score questions by smell severity
question_scores = []
for item in smells:
    high_count = sum(1 for s in item['smells'] if s['severity'] == 'HIGH')
    medium_count = sum(1 for s in item['smells'] if s['severity'] == 'MEDIUM')
    low_count = sum(1 for s in item['smells'] if s['severity'] == 'LOW')

    priority_score = high_count * 3 + medium_count * 2 + low_count * 1

    question_scores.append({
        'question': item['question'],
        'topic': item['topic'],
        'priority_score': priority_score,
        'high_severity': high_count,
        'medium_severity': medium_count,
        'total_smells': len(item['smells'])
    })

question_scores_df = pd.DataFrame(question_scores).sort_values('priority_score', ascending=False)

print("\nðŸŽ¯ Top 5 Questions Needing Revision (by smell severity):\n")
print(question_scores_df.head().to_string(index=False))

print("\n" + "=" * 80)
print("ANALYSIS COMPLETE")
print("=" * 80)

import os

# Create a directory to save the output files if it doesn't exist
output_dir = 'analysis_output'
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

# Save the summary_df to a CSV file
summary_output_path = os.path.join(output_dir, 'question_performance_summary.csv')
summary_df.to_csv(summary_output_path, index=False)
print(f"Saved question performance summary to: {summary_output_path}")

# Save the question_scores_df to a CSV file
priority_output_path = os.path.join(output_dir, 'priority_questions_for_revision.csv')
question_scores_df.to_csv(priority_output_path, index=False)
print(f"Saved priority questions for revision to: {priority_output_path}")

from google.colab import drive
drive.mount('/content/drive')
